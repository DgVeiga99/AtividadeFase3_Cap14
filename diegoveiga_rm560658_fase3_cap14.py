# -*- coding: utf-8 -*-
"""DiegoVeiga_RM560658_Fase3_Cap14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C6MeeGkuSzeIqhY8CC1E3FSlDDgex1oF

//=========================================================================

// ATIVIDADE FIAP - Cap 14 - A primeira técnica de aprendizado de máquina
//=========================================================================

// Autor.....: Diego Nunes Veiga

// RM........: 560658

// Turma.....: Graduação - 1TIAOR

// Data......: 11/11/2024

//==========================================================================
"""

# Importação das bibliotecas
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Carregar o dataset
df = pd.read_csv("Atividade_Cap_14_produtos_agricolas.csv")

# Exibir as primeiras linhas do DataFrame
df.head()

# Apresentação das informações gerais dos dados do arquivo
df.info()

# Verificar a presença de dados duplicados

duplicates = df.duplicated().sum()
print("Número de dados duplicados:", duplicates)

# Verificar a presença de outliers a partir da apresentação do Boxplot

plt.figure(figsize=(12, 6))
sns.boxplot(data=df)
plt.title("Detecção de outliers")
plt.xticks(rotation=45)
plt.show()

# Apresentação da distribuição dos labels

plt.figure(figsize=(10, 6))
sns.countplot(x='label', data=df)
plt.title("Tipos de plantações")
plt.xticks(rotation=45)
plt.show()

# Apresentação da matriz de correção

numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
plt.figure(figsize=(12, 8))
sns.heatmap(df.select_dtypes(include=numerics).corr(), annot=True, cmap='coolwarm')
plt.title("Matriz de Correlação")
plt.show()

"""# LIMPEZA DE DADOS"""

# Realiza o comando para retirar todos os outliers

outlier_counts = {}

for coluna in ['N','P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']:

    ExibeValor = True

    while True:

        # Calcular os limites do IQR
        Q1 = df[coluna].quantile(0.25)
        Q3 = df[coluna].quantile(0.75)
        IQR = Q3 - Q1
        limite_inferior = Q1 - 1.5 * IQR
        limite_superior = Q3 + 1.5 * IQR

        # Contar os outliers da coluna atual
        outliers = df[(df[coluna] < limite_inferior) | (df[coluna] > limite_superior)]
        num_outliers = len(outliers)

        # Coleta dados da qauntidade inicial de outliers
        if ExibeValor == True:
          outlier_counts[coluna] = len(outliers)
          ExibeValor = False

        # Verificar se ainda existem outliers
        if num_outliers == 0:
            break
        else:
            # Substituir os outliers pela mediana
            mediana = df[coluna].median()
            df[coluna] = df[coluna].apply(lambda x: mediana if x < limite_inferior or x > limite_superior else x)

# Exibir a quantidade de outliers para cada coluna
for coluna, count in outlier_counts.items():
    print(f"Coluna '{coluna}' possuia {count} outliers.")

# formatar o banco de dados
df.shape

# Verificar a presença de outliers a partir da apresentação do Boxplot

plt.figure(figsize=(12, 6))
sns.boxplot(data=df)
plt.title("Detecção de outliers")
plt.xticks(rotation=45)
plt.show()

# Separando features e labels
X = df.drop('label', axis=1)
y = df['label']

# Label Encoder para a variável alvo
le = LabelEncoder()
y = le.fit_transform(y)

"""# DADOS PARA TREINAMENTO E APROVAÇÃO"""

# Dividindo os dados em conjuntos de treino e teste (80% treino, 20% teste)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalização das features numéricas
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_teste_scaled = scaler.transform(X_test)

"""# CONSTRUÇÃO DOS MODELO PREDITIVOS"""

# Gera dicionário para armazenar as acurácias de cada modelo e posteriormente rankear
modelos = {}

# Regressão Logística

logreg = LogisticRegression()
logreg.fit(X_train_scaled, y_train)
y_pred_logreg = logreg.predict(X_teste_scaled)

# Resultados
ScoreRL = accuracy_score(y_test, y_pred_logreg)
print("Acurácia Regressão Logística:", ScoreRL)
print(classification_report(y_test, y_pred_logreg))

# Armazena valor
modelos ['Regressão Logística'] = ScoreRL

# KNN - 10 vizinhos

knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train_scaled, y_train)
y_pred_knn = knn.predict(X_teste_scaled)

# Resultados
ScoreKNN = accuracy_score(y_test, y_pred_knn)
print("Acurácia KNN:", ScoreKNN)
print(classification_report(y_test, y_pred_knn))

# Armazena valor
modelos ['KNN'] = ScoreKNN

# SVM com kernel RBF -> mais complexo
svm_rbf = SVC(kernel='rbf')
svm_rbf.fit(X_train_scaled, y_train)
y_pred_svm_rbf = svm_rbf.predict(X_teste_scaled)

# Resultados
ScoreSVM_RBF = accuracy_score(y_test, y_pred_svm_rbf)
print("Acurácia SVM (RBF):", ScoreSVM_RBF)
print(classification_report(y_test, y_pred_svm_rbf))

# Armazena valor
modelos ['SVM (RBF)'] = ScoreSVM_RBF

# SVM com kernel polinomial -> intermediário
svm_poly = SVC(kernel='poly')
svm_poly.fit(X_train_scaled, y_train)
y_pred_svm_poly = svm_poly.predict(X_teste_scaled)

# Resultados
ScoreSVM_P = accuracy_score(y_test, y_pred_svm_poly)
print("Acurácia SVM (Polinomial):", ScoreSVM_P )
print(classification_report(y_test, y_pred_svm_poly))

# Armazena valor
modelos ['SVM (Polinomial)'] = ScoreSVM_P

# SVM com kernel linear -> o mais simples
svm_linear = SVC(kernel='linear')
svm_linear.fit(X_train_scaled, y_train)
y_pred_svm_linear = svm_linear.predict(X_teste_scaled)

# Resultados
ScoreSVM_L = accuracy_score(y_test, y_pred_svm_linear)
print("Acurácia SVM (Linear):", ScoreSVM_L)
print(classification_report(y_test, y_pred_svm_linear))

# Armazena valor
modelos ['SVM (Linear)'] = ScoreSVM_L

# Decision Tree
dt = DecisionTreeClassifier()
dt.fit(X_train_scaled, y_train)
y_pred_dt = dt.predict(X_teste_scaled)

# Resultados
ScoreDT = accuracy_score(y_test, y_pred_dt)
print("Acurácia Decision Tree:", ScoreDT)
print(classification_report(y_test, y_pred_dt))

# Armazena valor
modelos ['Decision Tree'] = ScoreDT

# Random Forest
rf = RandomForestClassifier(n_estimators=25)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_teste_scaled)

# Resultados
ScoreRFO = accuracy_score(y_test, y_pred_rf)
print("Acurácia Random Forest:", ScoreRFO)
print(classification_report(y_test, y_pred_rf))

# Armazena valor
modelos ['Random Forest'] = ScoreRFO

# CONCLUSÃO

# Gerar o ranking das acurácias
ranking = sorted(modelos.items(), key=lambda x: x[1], reverse=True)

# Exibir o ranking
print("Ranking dos Mellhores Modelos:\n")
for i, (model, accuracy) in enumerate(ranking, 1):
    print(f"{i}. {model}: {accuracy:.4f}")